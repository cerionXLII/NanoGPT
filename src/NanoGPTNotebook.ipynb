{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/input.txt'\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Get all chracters of the dataset and create a vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a character to integer \n",
    "stoi = {x:i for i,x in enumerate(chars)}\n",
    "\n",
    "# And a integer to character\n",
    "itos = {i:x for x,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '$',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '3',\n",
       " 10: ':',\n",
       " 11: ';',\n",
       " 12: '?',\n",
       " 13: 'A',\n",
       " 14: 'B',\n",
       " 15: 'C',\n",
       " 16: 'D',\n",
       " 17: 'E',\n",
       " 18: 'F',\n",
       " 19: 'G',\n",
       " 20: 'H',\n",
       " 21: 'I',\n",
       " 22: 'J',\n",
       " 23: 'K',\n",
       " 24: 'L',\n",
       " 25: 'M',\n",
       " 26: 'N',\n",
       " 27: 'O',\n",
       " 28: 'P',\n",
       " 29: 'Q',\n",
       " 30: 'R',\n",
       " 31: 'S',\n",
       " 32: 'T',\n",
       " 33: 'U',\n",
       " 34: 'V',\n",
       " 35: 'W',\n",
       " 36: 'X',\n",
       " 37: 'Y',\n",
       " 38: 'Z',\n",
       " 39: 'a',\n",
       " 40: 'b',\n",
       " 41: 'c',\n",
       " 42: 'd',\n",
       " 43: 'e',\n",
       " 44: 'f',\n",
       " 45: 'g',\n",
       " 46: 'h',\n",
       " 47: 'i',\n",
       " 48: 'j',\n",
       " 49: 'k',\n",
       " 50: 'l',\n",
       " 51: 'm',\n",
       " 52: 'n',\n",
       " 53: 'o',\n",
       " 54: 'p',\n",
       " 55: 'q',\n",
       " 56: 'r',\n",
       " 57: 's',\n",
       " 58: 't',\n",
       " 59: 'u',\n",
       " 60: 'v',\n",
       " 61: 'w',\n",
       " 62: 'x',\n",
       " 63: 'y',\n",
       " 64: 'z'}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '$',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '3',\n",
       " 10: ':',\n",
       " 11: ';',\n",
       " 12: '?',\n",
       " 13: 'A',\n",
       " 14: 'B',\n",
       " 15: 'C',\n",
       " 16: 'D',\n",
       " 17: 'E',\n",
       " 18: 'F',\n",
       " 19: 'G',\n",
       " 20: 'H',\n",
       " 21: 'I',\n",
       " 22: 'J',\n",
       " 23: 'K',\n",
       " 24: 'L',\n",
       " 25: 'M',\n",
       " 26: 'N',\n",
       " 27: 'O',\n",
       " 28: 'P',\n",
       " 29: 'Q',\n",
       " 30: 'R',\n",
       " 31: 'S',\n",
       " 32: 'T',\n",
       " 33: 'U',\n",
       " 34: 'V',\n",
       " 35: 'W',\n",
       " 36: 'X',\n",
       " 37: 'Y',\n",
       " 38: 'Z',\n",
       " 39: 'a',\n",
       " 40: 'b',\n",
       " 41: 'c',\n",
       " 42: 'd',\n",
       " 43: 'e',\n",
       " 44: 'f',\n",
       " 45: 'g',\n",
       " 46: 'h',\n",
       " 47: 'i',\n",
       " 48: 'j',\n",
       " 49: 'k',\n",
       " 50: 'l',\n",
       " 51: 'm',\n",
       " 52: 'n',\n",
       " 53: 'o',\n",
       " 54: 'p',\n",
       " 55: 'q',\n",
       " 56: 'r',\n",
       " 57: 's',\n",
       " 58: 't',\n",
       " 59: 'u',\n",
       " 60: 'v',\n",
       " 61: 'w',\n",
       " 62: 'x',\n",
       " 63: 'y',\n",
       " 64: 'z'}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode a string character by character\n",
    "encode = lambda charstring: [stoi[c] for c in charstring]\n",
    "\n",
    "#Decode a list of integers to characters\n",
    "decode = lambda intlist: ''.join([itos[i] for i in intlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53, 57, 58, 51, 39, 41, 49, 39]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('ostmacka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ostmacka'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode('ostmacka'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
     ]
    }
   ],
   "source": [
    "#Encode our dataset into a torch tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "traing_data = data[:n]\n",
    "test_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How large our sequence is\n",
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, block_size, batch_size, device='cpu'):\n",
    "    ix = torch.randint(len(X)-block_size, (batch_size,))\n",
    "    x = torch.stack([X[i:i+block_size] for i in ix]).to(device)\n",
    "    y = torch.stack([X[i+1:i+block_size+1] for i in ix]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "xb, yb = get_batch(traing_data, block_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "        [25, 17, 27, 10,  0, 21,  1, 54]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "        [17, 27, 10,  0, 21,  1, 54, 39]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 15])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.tensor([[1,2],[1,2]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 15])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = embedding(xb).shape\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "xbow = wei @ embedding(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 15])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = key(x)\n",
    "q = query(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = q @ k.transpose(-2,-1) # (B, T, head_size) @ (B, head_size, T) --> (B, T, T)\n",
    "wei.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.4444e-01, -1.2236e-01,  3.0955e-01,  5.1334e-02,  1.3492e+00,\n",
       "          -8.6218e-01,  6.0017e-01, -7.5009e-02],\n",
       "         [-7.4904e-01,  3.0453e-01,  1.7004e-02, -6.1839e-02, -1.9661e+00,\n",
       "           8.1425e-01, -1.0588e-01,  3.5661e-01],\n",
       "         [-1.0378e+00,  1.7232e-01, -3.3471e-01,  3.6014e-01, -9.6117e-02,\n",
       "           2.7524e-01,  2.2733e-02,  5.8080e-02],\n",
       "         [ 4.6279e-01, -5.2776e-01,  4.7290e-01, -1.2831e-01,  7.5252e-02,\n",
       "          -3.9287e-01, -4.1890e-01, -5.1678e-01],\n",
       "         [ 8.9494e-02,  3.6058e-01, -7.3571e-01, -1.5041e-01,  7.4192e-01,\n",
       "           9.4202e-01,  1.1735e-01,  1.2284e+00],\n",
       "         [ 1.1788e+00, -8.8598e-01, -2.2477e-01,  5.6920e-01,  1.0682e+00,\n",
       "          -3.8678e-01,  5.0850e-01,  9.0173e-01],\n",
       "         [ 3.9176e-01, -5.7252e-01,  1.4949e+00, -4.5630e-01, -3.2381e-03,\n",
       "          -9.6991e-01,  2.0642e-01, -3.9829e-01],\n",
       "         [-5.4469e-02, -3.4297e-01, -8.8394e-02,  1.0209e+00,  7.5130e-01,\n",
       "          -7.4260e-01,  2.5856e-01, -2.2920e-01],\n",
       "         [ 4.5278e-01, -1.3078e-01,  1.1285e+00, -4.3931e-01, -1.5576e-01,\n",
       "          -4.6578e-01, -1.8558e-01, -4.2453e-01],\n",
       "         [ 4.9855e-01, -3.0721e-01, -4.2153e-01,  3.9841e-01,  3.2522e-01,\n",
       "          -9.8821e-01, -2.5774e-02, -5.1063e-01],\n",
       "         [-8.4964e-01,  6.1632e-01, -4.2495e-01, -4.2394e-01, -1.5623e-01,\n",
       "           1.2500e+00, -1.1056e-01,  9.1702e-01],\n",
       "         [-5.7395e-02, -5.3239e-01, -1.4625e-01,  1.4473e-01, -6.1509e-01,\n",
       "          -6.6472e-01, -7.8394e-02, -1.1648e-01],\n",
       "         [-7.2664e-01,  1.7730e-01,  1.5330e-01, -6.5057e-01, -2.4330e+00,\n",
       "          -1.3058e-01, -5.7525e-01, -1.1734e-02],\n",
       "         [-4.9063e-02, -1.5929e-01, -3.2751e-01, -4.7422e-02,  4.4446e-01,\n",
       "           1.0974e+00, -4.7149e-01,  3.8399e-02],\n",
       "         [-7.1876e-01,  5.1738e-01,  9.7324e-01,  3.1579e-01, -7.6416e-01,\n",
       "          -3.3826e-01,  8.2682e-02, -1.4399e+00],\n",
       "         [ 4.9231e-01, -1.3276e-01,  2.0682e-01,  1.0614e+00,  8.1725e-01,\n",
       "          -4.1195e-01,  5.6174e-01, -3.0469e-01]],\n",
       "\n",
       "        [[-2.8483e-01, -1.2752e+00,  9.7552e-01, -1.7503e-01, -1.9091e-01,\n",
       "          -4.4557e-01,  1.5451e-01, -7.8611e-02],\n",
       "         [ 5.9448e-01, -6.1633e-03,  7.8494e-02,  1.8063e-01,  5.6312e-01,\n",
       "           7.8841e-01, -3.6702e-01, -2.1069e-01],\n",
       "         [ 7.1758e-01,  6.0756e-01, -4.5905e-01, -1.0697e-01,  1.4101e-02,\n",
       "           9.4800e-02,  5.7160e-01,  2.3772e-01],\n",
       "         [-1.3861e-01,  3.9983e-01,  9.9955e-01, -3.4762e-01, -6.0096e-01,\n",
       "           3.6047e-01, -3.2979e-01,  7.1233e-01],\n",
       "         [-2.4541e-01, -5.4287e-01, -5.5952e-01, -9.7852e-02,  5.0570e-01,\n",
       "          -1.9784e-01,  4.8580e-01, -3.2337e-02],\n",
       "         [ 5.0187e-01, -3.7328e-01,  9.7294e-01, -9.3443e-01, -1.7630e+00,\n",
       "           1.0084e+00,  2.8794e-02,  5.1631e-01],\n",
       "         [-1.8388e-01,  2.5143e-01,  8.8324e-01,  4.8186e-02, -2.7781e-01,\n",
       "           1.2383e-01,  1.6455e-01,  2.9018e-01],\n",
       "         [ 2.6736e-01,  1.6634e-02,  1.1352e-01, -5.4044e-01, -9.9458e-01,\n",
       "           3.0746e-01, -1.4943e-01,  2.3216e-01],\n",
       "         [ 3.6441e-01, -2.4203e-01,  1.2262e+00,  8.5968e-02, -4.3965e-01,\n",
       "           7.1143e-01, -5.5591e-01,  6.8757e-01],\n",
       "         [-9.0458e-02, -7.6765e-01,  8.4020e-02,  4.7666e-01, -3.7567e-01,\n",
       "          -2.9459e-01, -6.1439e-01, -4.3203e-01],\n",
       "         [-2.1573e-02,  4.2143e-03, -1.2254e+00,  1.7380e-01,  1.1747e+00,\n",
       "           1.8729e-02,  3.0023e-01, -7.7325e-01],\n",
       "         [ 3.8109e-01,  4.5771e-01,  3.0035e-01,  1.3927e-01, -3.8023e-01,\n",
       "           1.3814e-01,  5.3007e-01, -1.1892e-01],\n",
       "         [-2.6211e-03,  5.5464e-01, -5.6032e-01,  7.8807e-01,  6.0667e-01,\n",
       "          -2.7549e-01,  1.1095e-01, -5.8185e-01],\n",
       "         [ 2.0820e-01, -5.7521e-01, -4.7446e-02, -4.0590e-01,  3.8576e-05,\n",
       "           5.7948e-01,  4.5190e-01,  1.0778e+00],\n",
       "         [-1.4732e-01,  4.6386e-01,  4.2719e-01,  6.4059e-01,  4.6584e-01,\n",
       "          -3.3491e-01, -9.9380e-01,  9.2128e-02],\n",
       "         [ 1.0043e-01, -3.4055e-01,  1.0135e+00, -8.5448e-01, -8.4083e-01,\n",
       "           4.1019e-01, -2.6852e-01,  8.9458e-01]],\n",
       "\n",
       "        [[ 2.9839e-01,  8.8240e-01,  3.7081e-01,  9.9185e-02,  1.4121e-01,\n",
       "          -4.4418e-01,  5.3922e-02, -5.1634e-01],\n",
       "         [-2.4307e-01, -2.7618e-01,  7.7370e-01,  3.2328e-01,  7.9276e-01,\n",
       "          -7.7409e-01, -5.7259e-01,  5.3161e-01],\n",
       "         [-1.0612e-01, -3.7539e-01,  8.1348e-01, -1.2472e+00, -5.0630e-01,\n",
       "           1.8123e-01, -4.2876e-01, -1.9725e+00],\n",
       "         [ 9.3202e-01,  2.5596e-01, -4.3159e-01,  1.1352e-02,  1.2203e-01,\n",
       "           5.2775e-02,  9.5638e-02, -2.3933e-01],\n",
       "         [-1.0917e-01,  4.6630e-01,  6.0562e-01, -1.1388e-01, -4.8505e-01,\n",
       "           3.0734e-01, -4.0489e-01, -1.1014e+00],\n",
       "         [ 1.0776e+00,  9.2055e-01, -5.0190e-01,  2.7826e-01, -1.7098e-01,\n",
       "           4.9268e-01,  2.7786e-01, -6.6890e-01],\n",
       "         [ 3.4508e-01, -1.3802e-01,  3.2722e-02, -1.0004e+00, -2.0028e-01,\n",
       "           1.8241e-01,  9.9056e-01, -1.0905e-01],\n",
       "         [ 2.7124e-01,  1.2448e-01, -1.3638e-02, -5.8749e-01, -4.5131e-01,\n",
       "           5.9410e-01,  2.2081e-01, -5.7510e-01],\n",
       "         [ 2.3451e-01,  1.1540e-01,  3.6808e-02, -4.8587e-01,  1.7254e-01,\n",
       "          -1.3962e+00, -2.2736e-01, -1.0090e+00],\n",
       "         [ 1.3646e-01,  3.3177e-02,  3.7324e-02,  4.8453e-01,  1.5536e-01,\n",
       "           1.0434e-01, -2.1190e-01,  2.5845e-02],\n",
       "         [-9.5490e-01,  3.5346e-01,  8.3962e-01, -2.5043e-01,  8.6904e-01,\n",
       "          -6.1916e-01, -8.5299e-01,  2.4163e-01],\n",
       "         [ 9.9227e-01,  2.3638e-01,  7.0536e-01, -1.2357e-01,  5.2292e-01,\n",
       "           6.0287e-01,  4.9292e-01, -2.7536e-01],\n",
       "         [-8.7534e-02, -1.4743e+00,  1.9146e-02,  2.4226e-01,  6.4622e-01,\n",
       "          -1.6570e-01,  5.6462e-02,  1.7110e+00],\n",
       "         [-3.2964e-01, -6.8535e-01, -4.6133e-01, -4.9946e-01,  7.0110e-01,\n",
       "          -7.7849e-01, -7.7527e-01, -9.3235e-01],\n",
       "         [-5.3157e-01, -3.4243e-01,  3.8788e-01, -3.4035e-01, -7.5047e-01,\n",
       "          -2.3596e-01,  5.4985e-01,  1.6763e-01],\n",
       "         [ 5.7084e-01,  5.1854e-01, -1.0565e-01, -1.7837e-02, -1.2374e+00,\n",
       "           6.8581e-01,  6.9141e-01, -8.3372e-01]],\n",
       "\n",
       "        [[ 6.5720e-01, -1.0906e+00, -5.6133e-01, -1.7529e-01, -4.4401e-01,\n",
       "           4.3535e-01, -1.4771e-02, -2.1989e-01],\n",
       "         [-7.1507e-02, -2.1062e-01,  7.7101e-01, -5.4575e-01,  5.4209e-02,\n",
       "          -3.3914e-01,  4.9578e-01, -1.6792e-01],\n",
       "         [ 1.3163e-01,  8.1108e-01, -1.0643e-01, -4.9120e-01, -9.8966e-02,\n",
       "          -5.8056e-01, -7.1097e-01,  1.1446e+00],\n",
       "         [ 2.0521e-01, -5.3559e-01, -4.2052e-01, -1.6198e-02,  6.0151e-01,\n",
       "           3.9396e-01,  1.7111e-01, -1.4547e-01],\n",
       "         [ 5.2132e-01,  1.0230e+00, -1.6432e-01, -3.4174e-01, -4.4077e-03,\n",
       "          -1.3848e+00, -6.4665e-01, -1.6963e-02],\n",
       "         [ 9.4089e-01, -3.7995e-01, -1.0067e+00, -3.4723e-01,  1.1098e-01,\n",
       "          -2.6620e-01,  2.6267e-01,  6.5836e-01],\n",
       "         [-3.4377e-01,  2.6345e-01, -4.6482e-01,  1.0503e+00,  4.1840e-01,\n",
       "           1.0564e+00,  3.5848e-02, -2.7638e-01],\n",
       "         [ 4.7300e-01, -7.7668e-01, -3.1530e-01, -8.5889e-01, -7.8680e-01,\n",
       "          -8.6633e-02,  1.5237e-01,  8.0719e-01],\n",
       "         [-5.1634e-01,  3.1194e-01, -9.6781e-01, -2.0046e-02,  9.5444e-01,\n",
       "           9.3925e-01,  3.4268e-01,  7.2446e-01],\n",
       "         [-6.1335e-02, -2.2643e-02,  2.2563e-01, -1.1364e+00, -3.4272e-02,\n",
       "           4.2509e-01, -4.8813e-01, -1.0394e-01],\n",
       "         [-2.7912e-01, -8.5870e-02,  5.5288e-01, -7.9069e-01, -4.6172e-01,\n",
       "          -1.3726e+00,  5.3072e-02, -7.6042e-01],\n",
       "         [ 8.5409e-01, -2.3908e-01, -2.9934e-02, -5.9242e-01,  4.2264e-01,\n",
       "          -8.9448e-02, -5.9559e-01, -1.3050e-01],\n",
       "         [-5.9005e-01,  7.6621e-01,  9.8272e-01,  1.1556e+00,  7.0926e-01,\n",
       "           1.0310e+00, -2.8156e-01, -6.3070e-01],\n",
       "         [ 1.3931e-01, -2.7597e-02, -1.4082e-01,  5.4588e-01,  7.8838e-01,\n",
       "          -5.8056e-01,  6.6142e-01,  4.6704e-01],\n",
       "         [-5.6818e-01, -1.6341e-01,  2.0523e-01, -4.9645e-01, -5.2630e-01,\n",
       "           3.7714e-01,  5.3110e-01,  2.9750e-01],\n",
       "         [ 9.3907e-01, -8.2795e-01, -6.3654e-01, -2.4377e-01, -7.4021e-01,\n",
       "          -2.8896e-02,  4.8734e-01,  1.0938e+00]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0140, -0.2557, -1.1456, -0.0650, -0.8981],\n",
       "         [ 0.6004, -0.0039,  0.9268, -0.9033, -1.8009],\n",
       "         [ 0.7865, -1.8513, -0.2894, -0.6531,  0.9476],\n",
       "         [-0.4904,  0.1995,  1.2089, -0.7427,  0.1015]],\n",
       "\n",
       "        [[-0.7365, -0.6101, -1.1973, -1.1110, -0.7467],\n",
       "         [-1.0201,  2.0264,  0.7080, -0.0137,  1.8259],\n",
       "         [ 1.5226,  0.6569, -1.7636, -0.7221, -0.9141],\n",
       "         [-0.8221, -1.6358, -1.3221, -1.2953, -0.6008]],\n",
       "\n",
       "        [[-0.9921, -0.2697,  0.1637,  2.1167, -0.9206],\n",
       "         [-0.6119, -0.4034,  0.3025,  0.6852, -1.0045],\n",
       "         [-1.0104, -1.0886, -0.9840,  0.5912, -1.1082],\n",
       "         [-1.2869, -0.8170,  0.9682,  1.6030, -0.0726]]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0140,  0.6004,  0.7865, -0.4904],\n",
       "         [-0.2557, -0.0039, -1.8513,  0.1995],\n",
       "         [-1.1456,  0.9268, -0.2894,  1.2089],\n",
       "         [-0.0650, -0.9033, -0.6531, -0.7427],\n",
       "         [-0.8981, -1.8009,  0.9476,  0.1015]],\n",
       "\n",
       "        [[-0.7365, -1.0201,  1.5226, -0.8221],\n",
       "         [-0.6101,  2.0264,  0.6569, -1.6358],\n",
       "         [-1.1973,  0.7080, -1.7636, -1.3221],\n",
       "         [-1.1110, -0.0137, -0.7221, -1.2953],\n",
       "         [-0.7467,  1.8259, -0.9141, -0.6008]],\n",
       "\n",
       "        [[-0.9921, -0.6119, -1.0104, -1.2869],\n",
       "         [-0.2697, -0.4034, -1.0886, -0.8170],\n",
       "         [ 0.1637,  0.3025, -0.9840,  0.9682],\n",
       "         [ 2.1167,  0.6852,  0.5912,  1.6030],\n",
       "         [-0.9206, -1.0045, -1.1082, -0.0726]]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1,2).allclose(x.transpose(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a self-attention head\n",
    "class Head(nn.Module):\n",
    "    \"\"\" \n",
    "    One single head of self-attention\n",
    "    block_size: The largest input length (number of tokens)\n",
    "    embed_size: The size of the embedding layer: token --> [embed_size]\n",
    "    head_size: The size of the key, query, value matrices ('Hidden state')\n",
    "    dropout_rate: The size of the dropout, used at training time\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, block_size, embed_size, head_size, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) #Lower triangular matrix used to mask out inputs of earlier times\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        \n",
    "        # Compute attention values, that is multiply query and keys\n",
    "        w = q @ k.transpose(-2,-1) * k.shape[-1]**(-0.5) # (B, T, C) @ (B, C, T) ---> (B, T, T) (Divided by sqrt of C to scale)\n",
    "        w = w.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T), adding -inf to values outside of the lower triangular part, that is to words that we havn't yet seen\n",
    "        w = F.softmax(w, dim=-1) # (B, T, T) #Softmax now takes the average of the values leading up to this time T\n",
    "        w = self.dropout(w) #Add dropout\n",
    "\n",
    "        #Multiply the output with the value matrix\n",
    "        out = w @ v # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "        return out    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, block_size, embed_size, head_size, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        # Simply create num_heads number of heads\n",
    "        self.heads = nn.ModuleList([Head(block_size, embed_size, head_size, dropout_rate) for _ in range(num_heads)])\n",
    "        self.FC = nn.Linear(head_size * num_heads, embed_size) #Fully connected layer\n",
    "        self.dropout = nn.Dropout(dropout_rate) #Dropout for regularization\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim = -1) #Simply concatinate the multiple heads\n",
    "        out = self.FC(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\" FC1 --> RELU --> FC2 --> Dropout \"\"\"\n",
    "    def __init__(self, embed_size, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_size, 4 * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_size, embed_size),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block\n",
    "        num_heads: The number of heads we use\n",
    "        block_size: The largest input length (number of tokens)\n",
    "        embed_size: The size of the embedding layer: token --> [embed_size]\n",
    "        head_size: The size of the key, query, value matrices ('Hidden state')\n",
    "        dropout_rate: The size of the dropout, used at training time    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads,  block_size, embed_size, dropout_rate):\n",
    "        super().__init__()\n",
    "        head_size = embed_size // num_heads\n",
    "        self.sa = MultiHeadAttention(num_heads, block_size, embed_size, head_size, dropout_rate)\n",
    "        self.ffwd = FeedForward(embed_size, dropout_rate)\n",
    "        self.layerNorm1 = nn.LayerNorm(embed_size)\n",
    "        self.layerNorm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.layerNorm1(x))\n",
    "        x = x + self.ffwd(self.layerNorm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, n_layers, vocab_size, num_heads, block_size, embed_size, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(block_size, embed_size)\n",
    "        self.blocks = nn.Sequential(*[Block(num_heads,  block_size, embed_size, dropout_rate) for _ in range(n_layers)])\n",
    "        self.layerNorm = nn.LayerNorm(embed_size)\n",
    "        self.FC = nn.Linear(embed_size, vocab_size)\n",
    "        self.block_size = block_size\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        device = idx.device\n",
    "\n",
    "        # Embed idx integers to embedding vectors for each token\n",
    "        tok_emb = self.token_embedding(idx) # (B, T, C)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=device)) #(T, C)\n",
    "\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.layerNorm(x) # (B, T, C)\n",
    "\n",
    "        logits = self.FC(x) # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            #loss = nn.CrossEntropyLoss(logits, targets)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.training(False)\n",
    "            for _ in range(max_new_tokens):\n",
    "\n",
    "                #Crop if we have too large input\n",
    "                idx_cond = idx[:, -self.block_size:]\n",
    "\n",
    "                logits, loss = self(idx_cond)\n",
    "\n",
    "                #Take last time step only\n",
    "                logits = logits[:, -1, :] #(B,1,C)\n",
    "\n",
    "                probs = F.softmax(logits, dim = -1) # (B,C)\n",
    "\n",
    "\n",
    "                #Sample from the distribution\n",
    "                idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "\n",
    "                #Append and concatinate\n",
    "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "\n",
    "        return idx \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 4\n",
    "num_heads = 4\n",
    "embed_size = 10\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = LanguageModel(n_layers, vocab_size, num_heads, block_size, embed_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006345 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (token_embedding): Embedding(65, 10)\n",
       "  (position_embedding): Embedding(8, 10)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (FC): Linear(in_features=8, out_features=10, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=10, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNorm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      (layerNorm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (FC): Linear(in_features=8, out_features=10, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=10, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNorm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      (layerNorm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (FC): Linear(in_features=8, out_features=10, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=10, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNorm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      (layerNorm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (query): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (value): Linear(in_features=10, out_features=2, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (FC): Linear(in_features=8, out_features=10, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=10, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNorm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      (layerNorm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layerNorm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (FC): Linear(in_features=10, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3794, val loss 4.3841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = {}\n",
    "        model.eval()\n",
    "        for data, name in zip([traing_data, test_data], ['train', 'val']):\n",
    "            loss_vect = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(data, block_size, batch_size, device)\n",
    "                logits, loss = model(X, Y)\n",
    "                loss_vect[k] = loss.item()\n",
    "            losses[name] = loss_vect.mean()\n",
    "        model.train()\n",
    "        \n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(traing_data, block_size, batch_size, device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n",
      "step 0: train loss 4.2221, val loss 4.2306\n",
      "step 500: train loss 1.7593, val loss 1.9105\n",
      "step 1000: train loss 1.3919, val loss 1.6024\n",
      "step 1500: train loss 1.2657, val loss 1.5220\n",
      "step 2000: train loss 1.1902, val loss 1.5081\n",
      "step 2500: train loss 1.1203, val loss 1.4913\n",
      "step 3000: train loss 1.0704, val loss 1.4884\n",
      "step 3500: train loss 1.0149, val loss 1.5022\n",
      "step 4000: train loss 0.9593, val loss 1.5195\n",
      "step 4500: train loss 0.9115, val loss 1.5456\n",
      "step 4999: train loss 0.8581, val loss 1.5775\n",
      "\n",
      "To enterpent you had now in his shame,\n",
      "And show himself, to look nose it.\n",
      "\n",
      "CORIOLANUS:\n",
      "Would that never dare did raze it?\n",
      "\n",
      "COMINIUS:\n",
      "Coriolanus.\n",
      "\n",
      "BRUTUS:\n",
      "Have you colld top child this?\n",
      "\n",
      "COMINIUS:\n",
      "It doth.\n",
      "Well, madam, my doe with you.\n",
      "\n",
      "COMINIUS:\n",
      "Pray not, here for affliction?\n",
      "This son myself disgrace these name up?\n",
      "\n",
      "First Senator:\n",
      "'Tis censure thou not to him.\n",
      "\n",
      "COMINIUS:\n",
      "Our pair o' the malking towards him; so saw'st\n",
      "thou, in battle. Here's worthless him to accident,\n",
      "for on Humblin an o' the sol\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('../data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
